{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4VhMzlmmG5A",
    "outputId": "82f9b3fc-53b3-452c-fe7f-161a43033a26"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4oHkub03moKC"
   },
   "outputs": [],
   "source": [
    "# FLOWERS_DIR ='/content/drive/Shareddrives/Visual Information Processing/FlowerData-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P4TeYXpXDYz4"
   },
   "outputs": [],
   "source": [
    "# path = '/content/drive/Shareddrives/Visual Information Processing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOWES_DIR = ''\n",
    "path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVwt7MBWm8Hx",
    "outputId": "ec4dbd92-1841-4fae-ab0a-d0be0ea2f2c3"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import io\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from six.moves import urllib\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk_metrics\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72DDJJsuMtUj"
   },
   "source": [
    "# Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkcE5fv-neLi"
   },
   "outputs": [],
   "source": [
    "TRAIN_FRACTION = 0.8\n",
    "RANDOM_SEED = 2018\n",
    "\n",
    "\n",
    "\n",
    "def make_train_and_test_sets():\n",
    "  \"\"\"Split the data into train and test sets and get the label classes.\"\"\"\n",
    "  train_examples, test_examples = [], []\n",
    "  shuffler = random.Random(RANDOM_SEED)\n",
    "  is_root = True\n",
    "  for (dirname, subdirs, filenames) in tf.gfile.Walk(FLOWERS_DIR):\n",
    "    # The root directory gives us the classes\n",
    "    if is_root:\n",
    "      subdirs = sorted(subdirs)\n",
    "      classes = collections.OrderedDict(enumerate(subdirs))\n",
    "      label_to_class = dict([(x, i) for i, x in enumerate(subdirs)])\n",
    "      is_root = False\n",
    "    # The sub directories give us the image files for training.\n",
    "    else:\n",
    "      filenames.sort()\n",
    "      shuffler.shuffle(filenames)\n",
    "      full_filenames = [os.path.join(dirname, f) for f in filenames]\n",
    "      label = dirname.split('/')[-1]\n",
    "      label_class = label_to_class[label]\n",
    "      # An example is the image file and it's label class.\n",
    "      examples = list(zip(full_filenames, [label_class] * len(filenames)))\n",
    "      num_train = int(len(filenames) * TRAIN_FRACTION)\n",
    "      train_examples.extend(examples[:num_train])\n",
    "      test_examples.extend(examples[num_train:])\n",
    "\n",
    "  shuffler.shuffle(train_examples)\n",
    "  shuffler.shuffle(test_examples)\n",
    "  return train_examples, test_examples, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HmgLTZ7MoOWz",
    "outputId": "ecc2abc2-a08a-4d3e-decd-d435ea062211"
   },
   "outputs": [],
   "source": [
    "# Split the images into train and test sets.\n",
    "\n",
    "TRAIN_EXAMPLES, TEST_EXAMPLES, CLASSES = make_train_and_test_sets()\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print('\\nThe dataset has %d label classes: %s' % (NUM_CLASSES, CLASSES.values()))\n",
    "print('There are %d training images' % len(TRAIN_EXAMPLES))\n",
    "print('there are %d test images' % len(TEST_EXAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sVbPEa-Kow5C",
    "outputId": "960e8c04-d959-4e04-a2b4-975945b66de2"
   },
   "outputs": [],
   "source": [
    "def get_label(example):\n",
    "  \"\"\"Get the label (number) for given example.\"\"\"\n",
    "  return example[1]\n",
    "\n",
    "def get_class(example):\n",
    "  \"\"\"Get the class (string) of given example.\"\"\"\n",
    "  return CLASSES[get_label(example)]\n",
    "\n",
    "def get_encoded_image(example):\n",
    "  \"\"\"Get the image data (encoded jpg) of given example.\"\"\"\n",
    "  image_path = example[0]\n",
    "  return tf.gfile.GFile(image_path, 'rb').read()\n",
    "\n",
    "def get_image(example):\n",
    "  \"\"\"Get image as np.array of pixels for given example.\"\"\"\n",
    "  return plt.imread(io.BytesIO(get_encoded_image(example)), format='jpg')\n",
    "\n",
    "def display_images(images_and_classes, cols=5):\n",
    "  \"\"\"Display given images and their labels in a grid.\"\"\"\n",
    "  rows = int(math.ceil(len(images_and_classes) / cols))\n",
    "  fig = plt.figure()\n",
    "  fig.set_size_inches(cols * 3, rows * 3)\n",
    "  for i, (image, flower_class) in enumerate(images_and_classes):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(flower_class)\n",
    "\n",
    "NUM_IMAGES = 50\n",
    "display_images([(get_image(example), get_class(example))\n",
    "               for example in TRAIN_EXAMPLES[:NUM_IMAGES]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6C_Xhi4KWgp"
   },
   "source": [
    "# MobileNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njQogfRVwS_X",
    "outputId": "34b5382a-bf37-4266-f176-b955aaf2f0fe"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Load a pre-trained TF-Hub module for extracting features from images. We've\n",
    "# chosen this particular module for speed, but many other choices are available.\n",
    "image_module = hub.Module('https://tfhub.dev/google/imagenet/mobilenet_v2_050_128/feature_vector/3', trainable=True, tags={\"train\"})\n",
    "\n",
    "# Preprocessing images into tensors with size expected by the image module.\n",
    "encoded_images = tf.placeholder(tf.string, shape=[None])\n",
    "image_size = hub.get_expected_image_size(image_module)\n",
    "\n",
    "\n",
    "def decode_and_resize_image(encoded):\n",
    "  decoded = tf.image.decode_jpeg(encoded, channels=3)\n",
    "  decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "  return tf.image.resize_images(decoded, image_size)\n",
    "\n",
    "\n",
    "batch_images = tf.map_fn(decode_and_resize_image, encoded_images, dtype=tf.float32)\n",
    "\n",
    "# The image module can be applied as a function to extract feature vectors for a\n",
    "# batch of images.\n",
    "features = image_module(inputs=dict(images=batch_images, batch_norm_momentum=0.997),\n",
    "                  signature=\"image_feature_vector_with_bn_hparams\")\n",
    "\n",
    "def create_model(features):\n",
    "  \"\"\"Build a model for classification from extracted features.\"\"\"\n",
    "  # Currently, the model is just a single linear layer. You can try to add\n",
    "  # another layer, but be careful... two linear layers (when activation=None)\n",
    "  # are equivalent to a single linear layer. You can create a nonlinear layer\n",
    "  # like this:\n",
    "  # layer = tf.layers.dense(inputs=..., units=..., activation=tf.nn.relu)\n",
    "  \n",
    "  layer = tf.layers.dense(inputs=features, units=NUM_CLASSES, activation=None)\n",
    "  return layer\n",
    "\n",
    "\n",
    "# For each class (kind of flower), the model outputs some real number as a score\n",
    "# how much the input resembles this class. This vector of numbers is often\n",
    "# called the \"logits\".\n",
    "logits = create_model(features)\n",
    "labels = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
    "\n",
    "# Mathematically, a good way to measure how much the predicted probabilities\n",
    "# diverge from the truth is the \"cross-entropy\" between the two probability\n",
    "# distributions. For numerical stability, this is best done directly from the\n",
    "# logits, not the probabilities extracted from them.\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
    "cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Let's add an optimizer so we can train the network.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "train_op = optimizer.minimize(loss=cross_entropy_mean)\n",
    "\n",
    "# The \"softmax\" function transforms the logits vector into a vector of\n",
    "# probabilities: non-negative numbers that sum up to one, and the i-th number\n",
    "# says how likely the input comes from class i.\n",
    "probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "# We choose the highest one as the predicted class.\n",
    "prediction = tf.argmax(probabilities, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(labels, 1))\n",
    "\n",
    "# The accuracy will allow us to eval on our test set. \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTGBavjNbcO6",
    "outputId": "36b1e389-9395-4fce-a251-b86a0211ca8e"
   },
   "outputs": [],
   "source": [
    "# How long will we train the network (number of batches).\n",
    "NUM_TRAIN_STEPS = 100\n",
    "# How many training examples we use in each step.\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "# How often to evaluate the model performance.\n",
    "EVAL_EVERY = 10\n",
    "\n",
    "def get_batch(batch_size=None, test=False):\n",
    "  \"\"\"Get a random batch of examples.\"\"\"\n",
    "  examples = TEST_EXAMPLES if test else TRAIN_EXAMPLES\n",
    "  batch_examples = random.sample(examples, batch_size) if batch_size else examples\n",
    "  return batch_examples\n",
    "\n",
    "def get_images_and_labels(batch_examples):\n",
    "  images = [get_encoded_image(e) for e in batch_examples]\n",
    "  one_hot_labels = [get_label_one_hot(e) for e in batch_examples]\n",
    "  return images, one_hot_labels\n",
    "\n",
    "def get_label_one_hot(example):\n",
    "  \"\"\"Get the one hot encoding vector for the example.\"\"\"\n",
    "  one_hot_vector = np.zeros(NUM_CLASSES)\n",
    "  np.put(one_hot_vector, get_label(example), 1)\n",
    "  return one_hot_vector\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for i in range(NUM_TRAIN_STEPS):\n",
    "    # Get a random batch of training examples.\n",
    "    train_batch = get_batch(batch_size=TRAIN_BATCH_SIZE)\n",
    "    batch_images, batch_labels = get_images_and_labels(train_batch)\n",
    "    # Run the train_op to train the model.\n",
    "    train_loss, _, train_accuracy = sess.run(\n",
    "        [cross_entropy_mean, train_op, accuracy],\n",
    "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
    "    is_final_step = (i == (NUM_TRAIN_STEPS - 1))\n",
    "    if i % EVAL_EVERY == 0 or is_final_step:\n",
    "      # Get a batch of test examples.\n",
    "      test_batch = get_batch(batch_size=None, test=True)\n",
    "      batch_images, batch_labels = get_images_and_labels(test_batch)\n",
    "      # Evaluate how well our model performs on the test set.\n",
    "      test_loss, test_accuracy, test_prediction, correct_predicate = sess.run(\n",
    "        [cross_entropy_mean, accuracy, prediction, correct_prediction],\n",
    "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
    "      print('Test accuracy at step %s: %.2f%%' % (i, (test_accuracy * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VmMmI5nKlzBK",
    "outputId": "4d24295f-e3bd-4a64-b3f5-7568d47f05a3"
   },
   "outputs": [],
   "source": [
    "mobilenet_accuracy = round(test_accuracy * 100, 2)\n",
    "mobilenet_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4_n_Ofva9CWP",
    "outputId": "fddfed8a-58f0-4b10-b8f9-1c37964debee"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(test_labels, predictions):\n",
    "  \"\"\"Compute confusion matrix and normalize.\"\"\"\n",
    "  confusion = sk_metrics.confusion_matrix(\n",
    "    np.argmax(test_labels, axis=1), predictions)\n",
    "  confusion_normalized = confusion.astype(\"float\") / confusion.sum(axis=1)\n",
    "  axis_labels = list(CLASSES.values())\n",
    "  plt.figure(figsize=(20,16))\n",
    "\n",
    "  ax = sns.heatmap(\n",
    "      confusion_normalized, xticklabels=axis_labels, yticklabels=axis_labels,\n",
    "      cmap='Blues', annot=True, fmt='.2f', square=True)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.ylabel(\"True label\")\n",
    "  plt.xlabel(\"Predicted label\")\n",
    "  \n",
    "\n",
    "show_confusion_matrix(batch_labels, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "xzaOzBh6_AHX",
    "outputId": "a545d770-1474-48d8-9d2f-631bf24f8d7a"
   },
   "outputs": [],
   "source": [
    "incorrect = [\n",
    "    (example, CLASSES[prediction])\n",
    "    for example, prediction, is_correct in zip(test_batch, test_prediction, correct_predicate)\n",
    "    if not is_correct\n",
    "]\n",
    "display_images(\n",
    "  [(get_image(example), \"prediction: {0}\\nlabel:{1}\".format(incorrect_prediction, get_class(example)))\n",
    "   for (example, incorrect_prediction) in incorrect[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLjmcyjDlTeg",
    "outputId": "a93905da-7410-4190-fbdf-b1818bbeb63e"
   },
   "outputs": [],
   "source": [
    "mobilenet_error = len(incorrect)\n",
    "print(mobilenet_error, \" \\ \", len(test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHg7wpg6jZhf"
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1b9FLljKwtg"
   },
   "source": [
    "# ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RovqfAXhKwtg",
    "outputId": "af29bb50-d8a0-4734-b8c4-7b9937d9cc5c"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Load a pre-trained TF-Hub module for extracting features from images. We've\n",
    "# chosen this particular module for speed, but many other choices are available.\n",
    "image_module = hub.Module('https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/3', trainable=True, tags={\"train\"})\n",
    "\n",
    "\n",
    "# Preprocessing images into tensors with size expected by the image module.\n",
    "encoded_images = tf.placeholder(tf.string, shape=[None])\n",
    "image_size = hub.get_expected_image_size(image_module)\n",
    "\n",
    "\n",
    "def decode_and_resize_image(encoded):\n",
    "  decoded = tf.image.decode_jpeg(encoded, channels=3)\n",
    "  decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "  return tf.image.resize_images(decoded, image_size)\n",
    "\n",
    "\n",
    "batch_images = tf.map_fn(decode_and_resize_image, encoded_images, dtype=tf.float32)\n",
    "\n",
    "# The image module can be applied as a function to extract feature vectors for a\n",
    "# batch of images.\n",
    "features = image_module(inputs=dict(images=batch_images, batch_norm_momentum=0.997),\n",
    "                  signature=\"image_feature_vector_with_bn_hparams\")\n",
    "\n",
    "def create_model(features):\n",
    "  \"\"\"Build a model for classification from extracted features.\"\"\"\n",
    "  # Currently, the model is just a single linear layer. You can try to add\n",
    "  # another layer, but be careful... two linear layers (when activation=None)\n",
    "  # are equivalent to a single linear layer. You can create a nonlinear layer\n",
    "  # like this:\n",
    "  # layer = tf.layers.dense(inputs=..., units=..., activation=tf.nn.relu)\n",
    "  \n",
    "  layer = tf.layers.dense(inputs=features, units=NUM_CLASSES, activation=None)\n",
    "  return layer\n",
    "\n",
    "\n",
    "# For each class (kind of flower), the model outputs some real number as a score\n",
    "# how much the input resembles this class. This vector of numbers is often\n",
    "# called the \"logits\".\n",
    "logits = create_model(features)\n",
    "labels = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
    "\n",
    "# Mathematically, a good way to measure how much the predicted probabilities\n",
    "# diverge from the truth is the \"cross-entropy\" between the two probability\n",
    "# distributions. For numerical stability, this is best done directly from the\n",
    "# logits, not the probabilities extracted from them.\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
    "cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Let's add an optimizer so we can train the network.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "train_op = optimizer.minimize(loss=cross_entropy_mean)\n",
    "\n",
    "# The \"softmax\" function transforms the logits vector into a vector of\n",
    "# probabilities: non-negative numbers that sum up to one, and the i-th number\n",
    "# says how likely the input comes from class i.\n",
    "probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "# We choose the highest one as the predicted class.\n",
    "prediction = tf.argmax(probabilities, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(labels, 1))\n",
    "\n",
    "# The accuracy will allow us to eval on our test set. \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPr_sFRLKwth",
    "outputId": "4f08db72-6c13-4db3-d32c-3aa680204ece"
   },
   "outputs": [],
   "source": [
    "# How long will we train the network (number of batches).\n",
    "NUM_TRAIN_STEPS = 100\n",
    "# How many training examples we use in each step.\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "# How often to evaluate the model performance.\n",
    "EVAL_EVERY = 10\n",
    "\n",
    "def get_batch(batch_size=None, test=False):\n",
    "  \"\"\"Get a random batch of examples.\"\"\"\n",
    "  examples = TEST_EXAMPLES if test else TRAIN_EXAMPLES\n",
    "  batch_examples = random.sample(examples, batch_size) if batch_size else examples\n",
    "  return batch_examples\n",
    "\n",
    "def get_images_and_labels(batch_examples):\n",
    "  images = [get_encoded_image(e) for e in batch_examples]\n",
    "  one_hot_labels = [get_label_one_hot(e) for e in batch_examples]\n",
    "  return images, one_hot_labels\n",
    "\n",
    "def get_label_one_hot(example):\n",
    "  \"\"\"Get the one hot encoding vector for the example.\"\"\"\n",
    "  one_hot_vector = np.zeros(NUM_CLASSES)\n",
    "  np.put(one_hot_vector, get_label(example), 1)\n",
    "  return one_hot_vector\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for i in range(NUM_TRAIN_STEPS):\n",
    "    # Get a random batch of training examples.\n",
    "    train_batch = get_batch(batch_size=TRAIN_BATCH_SIZE)\n",
    "    batch_images, batch_labels = get_images_and_labels(train_batch)\n",
    "    # Run the train_op to train the model.\n",
    "    train_loss, _, train_accuracy = sess.run(\n",
    "        [cross_entropy_mean, train_op, accuracy],\n",
    "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
    "    is_final_step = (i == (NUM_TRAIN_STEPS - 1))\n",
    "    if i % EVAL_EVERY == 0 or is_final_step:\n",
    "      # Get a batch of test examples.\n",
    "      test_batch = get_batch(batch_size=None, test=True)\n",
    "      batch_images, batch_labels = get_images_and_labels(test_batch)\n",
    "      # Evaluate how well our model performs on the test set.\n",
    "      test_loss, test_accuracy, test_prediction, correct_predicate = sess.run(\n",
    "        [cross_entropy_mean, accuracy, prediction, correct_prediction],\n",
    "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
    "      print('Test accuracy at step %s: %.2f%%' % (i, (test_accuracy * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYxYfEKIKwth",
    "outputId": "9f034a01-0735-4fad-bd3c-a80aa644a432"
   },
   "outputs": [],
   "source": [
    "resnet_accuracy = round(test_accuracy * 100, 2)\n",
    "resnet_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OyZgrxXmKwti",
    "outputId": "8285a808-753b-4ae6-edab-cc830faa3536"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(test_labels, predictions):\n",
    "  \"\"\"Compute confusion matrix and normalize.\"\"\"\n",
    "  confusion = sk_metrics.confusion_matrix(\n",
    "    np.argmax(test_labels, axis=1), predictions)\n",
    "  confusion_normalized = confusion.astype(\"float\") / confusion.sum(axis=1)\n",
    "  axis_labels = list(CLASSES.values())\n",
    "  plt.figure(figsize=(20,16))\n",
    "\n",
    "  ax = sns.heatmap(\n",
    "      confusion_normalized, xticklabels=axis_labels, yticklabels=axis_labels,\n",
    "      cmap='Blues', annot=True, fmt='.2f', square=True)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.ylabel(\"True label\")\n",
    "  plt.xlabel(\"Predicted label\")\n",
    "  \n",
    "\n",
    "show_confusion_matrix(batch_labels, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "nAuS75HzKwtj",
    "outputId": "8c9834a2-065e-41e1-a38f-590de644881f"
   },
   "outputs": [],
   "source": [
    "incorrect = [\n",
    "    (example, CLASSES[prediction])\n",
    "    for example, prediction, is_correct in zip(test_batch, test_prediction, correct_predicate)\n",
    "    if not is_correct\n",
    "]\n",
    "display_images(\n",
    "  [(get_image(example), \"prediction: {0}\\nlabel:{1}\".format(incorrect_prediction, get_class(example)))\n",
    "   for (example, incorrect_prediction) in incorrect[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93yYe9ye8Kt2",
    "outputId": "ef3a4aa0-cbc3-4359-c010-928394cafdbe"
   },
   "outputs": [],
   "source": [
    "resnet_error = len(incorrect)\n",
    "print(resnet_error, \" \\ \", len(test_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldTS8uI6LPXj"
   },
   "source": [
    "# Inception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zp7iiwa0LPXk",
    "outputId": "37d74232-1479-4a3d-ef2c-f4fec14a502c"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Load a pre-trained TF-Hub module for extracting features from images. We've\n",
    "# chosen this particular module for speed, but many other choices are available.\n",
    "image_module = hub.Module('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/3', trainable=True, tags={\"train\"})\n",
    "\n",
    "# Preprocessing images into tensors with size expected by the image module.\n",
    "encoded_images = tf.placeholder(tf.string, shape=[None])\n",
    "image_size = hub.get_expected_image_size(image_module)\n",
    "\n",
    "\n",
    "def decode_and_resize_image(encoded):\n",
    "  decoded = tf.image.decode_jpeg(encoded, channels=3)\n",
    "  decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "  return tf.image.resize_images(decoded, image_size)\n",
    "\n",
    "\n",
    "batch_images = tf.map_fn(decode_and_resize_image, encoded_images, dtype=tf.float32)\n",
    "\n",
    "# The image module can be applied as a function to extract feature vectors for a\n",
    "# batch of images.\n",
    "features = image_module(inputs=dict(images=batch_images, batch_norm_momentum=0.997),\n",
    "                  signature=\"image_feature_vector_with_bn_hparams\")\n",
    "\n",
    "def create_model(features):\n",
    "  \"\"\"Build a model for classification from extracted features.\"\"\"\n",
    "  # Currently, the model is just a single linear layer. You can try to add\n",
    "  # another layer, but be careful... two linear layers (when activation=None)\n",
    "  # are equivalent to a single linear layer. You can create a nonlinear layer\n",
    "  # like this:\n",
    "  # layer = tf.layers.dense(inputs=..., units=..., activation=tf.nn.relu)\n",
    "  \n",
    "  layer = tf.layers.dense(inputs=features, units=NUM_CLASSES, activation=None)\n",
    "  return layer\n",
    "\n",
    "\n",
    "# For each class (kind of flower), the model outputs some real number as a score\n",
    "# how much the input resembles this class. This vector of numbers is often\n",
    "# called the \"logits\".\n",
    "logits = create_model(features)\n",
    "labels = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
    "\n",
    "# Mathematically, a good way to measure how much the predicted probabilities\n",
    "# diverge from the truth is the \"cross-entropy\" between the two probability\n",
    "# distributions. For numerical stability, this is best done directly from the\n",
    "# logits, not the probabilities extracted from them.\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
    "cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Let's add an optimizer so we can train the network.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "train_op = optimizer.minimize(loss=cross_entropy_mean)\n",
    "\n",
    "# The \"softmax\" function transforms the logits vector into a vector of\n",
    "# probabilities: non-negative numbers that sum up to one, and the i-th number\n",
    "# says how likely the input comes from class i.\n",
    "probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "# We choose the highest one as the predicted class.\n",
    "prediction = tf.argmax(probabilities, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(labels, 1))\n",
    "\n",
    "# The accuracy will allow us to eval on our test set. \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBJ5CCA7LPXk",
    "outputId": "7d9d100e-8df9-477c-e27e-a12c675c1556"
   },
   "outputs": [],
   "source": [
    "# How long will we train the network (number of batches).\n",
    "NUM_TRAIN_STEPS = 100\n",
    "# How many training examples we use in each step.\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "# How often to evaluate the model performance.\n",
    "EVAL_EVERY = 10\n",
    "\n",
    "def get_batch(batch_size=None, test=False):\n",
    "  \"\"\"Get a random batch of examples.\"\"\"\n",
    "  examples = TEST_EXAMPLES if test else TRAIN_EXAMPLES\n",
    "  batch_examples = random.sample(examples, batch_size) if batch_size else examples\n",
    "  return batch_examples\n",
    "\n",
    "def get_images_and_labels(batch_examples):\n",
    "  images = [get_encoded_image(e) for e in batch_examples]\n",
    "  one_hot_labels = [get_label_one_hot(e) for e in batch_examples]\n",
    "  return images, one_hot_labels\n",
    "\n",
    "def get_label_one_hot(example):\n",
    "  \"\"\"Get the one hot encoding vector for the example.\"\"\"\n",
    "  one_hot_vector = np.zeros(NUM_CLASSES)\n",
    "  np.put(one_hot_vector, get_label(example), 1)\n",
    "  return one_hot_vector\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for i in range(NUM_TRAIN_STEPS):\n",
    "    # Get a random batch of training examples.\n",
    "    train_batch = get_batch(batch_size=TRAIN_BATCH_SIZE)\n",
    "    batch_images, batch_labels = get_images_and_labels(train_batch)\n",
    "    # Run the train_op to train the model.\n",
    "    train_loss, _, train_accuracy = sess.run(\n",
    "        [cross_entropy_mean, train_op, accuracy],\n",
    "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
    "    is_final_step = (i == (NUM_TRAIN_STEPS - 1))\n",
    "    if i % EVAL_EVERY == 0 or is_final_step:\n",
    "      # Get a batch of test examples.\n",
    "      test_batch = get_batch(batch_size=None, test=True)\n",
    "      batch_images, batch_labels = get_images_and_labels(test_batch)\n",
    "      # Evaluate how well our model performs on the test set.\n",
    "      test_loss, test_accuracy, test_prediction, correct_predicate = sess.run(\n",
    "        [cross_entropy_mean, accuracy, prediction, correct_prediction],\n",
    "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
    "      print('Test accuracy at step %s: %.2f%%' % (i, (test_accuracy * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvZDgtXoLPXl",
    "outputId": "6e0681c5-f0f5-484d-d5c6-cee49c05c07f"
   },
   "outputs": [],
   "source": [
    "inceptionv3_accuracy = round(test_accuracy * 100, 2)\n",
    "inceptionv3_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_DBXwjwNLPXm",
    "outputId": "4a45541d-59c1-4a1b-df94-5d6c9ee87634"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(test_labels, predictions):\n",
    "  \"\"\"Compute confusion matrix and normalize.\"\"\"\n",
    "  confusion = sk_metrics.confusion_matrix(\n",
    "    np.argmax(test_labels, axis=1), predictions)\n",
    "  confusion_normalized = confusion.astype(\"float\") / confusion.sum(axis=1)\n",
    "  axis_labels = list(CLASSES.values())\n",
    "  plt.figure(figsize=(20,16))\n",
    "\n",
    "  ax = sns.heatmap(\n",
    "      confusion_normalized, xticklabels=axis_labels, yticklabels=axis_labels,\n",
    "      cmap='Blues', annot=True, fmt='.2f', square=True)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.ylabel(\"True label\")\n",
    "  plt.xlabel(\"Predicted label\")\n",
    "  \n",
    "\n",
    "show_confusion_matrix(batch_labels, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "deE5IYPNLPXm",
    "outputId": "84787fbd-511a-4354-e4fb-163e926dba62"
   },
   "outputs": [],
   "source": [
    "incorrect = [\n",
    "    (example, CLASSES[prediction])\n",
    "    for example, prediction, is_correct in zip(test_batch, test_prediction, correct_predicate)\n",
    "    if not is_correct\n",
    "]\n",
    "display_images(\n",
    "  [(get_image(example), \"prediction: {0}\\nlabel:{1}\".format(incorrect_prediction, get_class(example)))\n",
    "   for (example, incorrect_prediction) in incorrect[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXfmWnU38M75",
    "outputId": "02142178-db9f-4044-b682-3548b1c1b1c8"
   },
   "outputs": [],
   "source": [
    "inceptionv3_error = len(incorrect)\n",
    "print(inceptionv3_error, \" \\ \", len(test_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMcxFtWvMXtU"
   },
   "source": [
    "# Result table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "1iubD4uHmK9S",
    "outputId": "97949a6a-4894-40c0-db41-1229593be83a"
   },
   "outputs": [],
   "source": [
    "comparison_accuracy = pd.DataFrame([['MobileNet', 88.6, mobilenet_accuracy], ['ResNet', 89.0, resnet_accuracy], ['InceptionV3', 85.2, inceptionv3_accuracy]],\n",
    "                   columns=['Model', 'Without Finetune', 'Finetuned'])\n",
    "comparison_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8r90uMO5LPXl"
   },
   "outputs": [],
   "source": [
    "comparison_accuracy.to_csv(path+'Eval_Accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3hXuCDnDGW4"
   },
   "outputs": [],
   "source": [
    "mobilenet_error = 39\n",
    "resnet_error=29\n",
    "inceptionv3_error=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "65OpmgvIBUqD",
    "outputId": "fa3b7530-3553-4bb9-f477-f58b746d72a2"
   },
   "outputs": [],
   "source": [
    "comparison_error = pd.DataFrame([['MobileNet', 57, mobilenet_error], ['ResNet', 55, resnet_error], ['InceptionV3', 74, inceptionv3_error]],\n",
    "                   columns=['Model', 'Without Finetune', 'Finetuned'])\n",
    "comparison_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntZqnTSDDoEL"
   },
   "outputs": [],
   "source": [
    "comparison_error.to_csv(path+'Eval_Error.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "Jg7UttvOFD7b",
    "outputId": "98d8e4a7-c5ce-49c7-980d-a33417a4960a"
   },
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame([['MobileNet', 88.6, \"Without Finetune\"], ['MobileNet', mobilenet_accuracy, \"Finetuned\"], ['ResNet', 89.0, \"Without Finetune\"], ['ResNet', resnet_accuracy, \"Finetuned\"], ['InceptionV3', 85.2, \"Without Finetune\"], ['InceptionV3', inceptionv3_accuracy, \"Finetuned\"]],\n",
    "                   columns=['Model', 'Accuracy', 'Type'])\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "KY842dcwFt1c",
    "outputId": "016c42a3-0b0b-4c78-dd37-02a90c813204"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8)), plt.title('Accuracy Comparison for each model')\n",
    "ax = sns.barplot(x=\"Model\", y=\"Accuracy\", hue=\"Type\", data=comparison)\n",
    "plt.legend(loc='lower center')\n",
    "ax.set(ylim=(75, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "rw9QDNi4EdvV",
    "outputId": "12e4be09-635f-4f2f-d6e1-5ab3f61cccea"
   },
   "outputs": [],
   "source": [
    "error = pd.DataFrame([['MobileNet', 57, \"Without Finetune\"], ['MobileNet', mobilenet_error, \"Finetuned\"], ['ResNet', 55, \"Without Finetune\"], ['ResNet', resnet_error, \"Finetuned\"], ['InceptionV3', 74, \"Without Finetune\"], ['InceptionV3', inceptionv3_error, \"Finetuned\"]],\n",
    "                   columns=['Model', 'No. of Error', 'Type'])\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "Bdtzf1XCKH_4",
    "outputId": "e8383993-6388-43a7-a2af-8898e7048ea6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8)), plt.title('No. of Error Comparison for each model')\n",
    "ax = sns.barplot(x=\"Model\", y=\"No. of Error\", hue=\"Type\", data=error)\n",
    "plt.legend(loc='lower center')\n",
    "#ax.set(ylim=(75, 100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "C1b9FLljKwtg",
    "ldTS8uI6LPXj",
    "zMcxFtWvMXtU"
   ],
   "name": "Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Anaconda (base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
